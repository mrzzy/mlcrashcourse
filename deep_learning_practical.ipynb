{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlcrashcourse - Deep Learning Practical\n",
    "\n",
    "In this practical, we explore the use of a neural network for convolution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (InputLayer, Dense, BatchNormalization, Dense, Dropout, \n",
    "                                     Conv2D, Flatten, MaxPool2D)\n",
    "from tensorflow.keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the problem\n",
    "\n",
    "Link to dataset: https://www.kaggle.com/zalando-research/fashionmnist\n",
    "\n",
    "In this practical we will be using the **Fashion MNIST** dataset. The task is to classify the image into the different fashion classes/labels. \n",
    "\n",
    "> Basically, given an image of a boot, the model should be able to tell me that that is a boot.\n",
    "\n",
    "| No. Label | Text Label |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "\n",
    "\n",
    "This is a supervised problem because there is a expected output we want to obtain from the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Now we proceed with loading the data.\n",
    "Thankfully, Keras provides use with a simple way to access the data. Already, most of work is already done for us by Keras:\n",
    "\n",
    "1. Reading the images into numpy arrays\n",
    "2. Converting the labels into integers representing them\n",
    "3. Splitting the dataset in train, test subsets for later model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training examples, 10000 test examples\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "# load the data using keras datasets\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "print(f\"{len(train_images)} training examples, {len(test_images)} test examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at a random image and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a: Ankle boot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb1e88d4e80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = randint(0, len(train_images))\n",
    "image = train_images[idx]\n",
    "label_i = train_labels[idx]\n",
    "print(\"This is a:\", label_map[label_i])\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "Neural Networks are fussy with the data that they take in, so we need to do some preprocessing:\n",
    "1. Apply Feature Scaling to the images\n",
    "2. One hot encode the labels\n",
    "\n",
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzy/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/zzy/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/zzy/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Perform feature scaling with standard scaler \n",
    "# np.reshape() is needed to ensure that the np arrays have the correct shape\n",
    "n_images = len(train_images)\n",
    "scaler = StandardScaler()\n",
    "flat_train_images = np.reshape(train_images, (n_images, -1))\n",
    "\n",
    "# we need to tell the scaler about what data it will be dealing with\n",
    "scaler.fit(flat_train_images)\n",
    "\n",
    "# Define a function to scale features\n",
    "def scale_features(images):\n",
    "    flat_images = np.reshape(images, (len(images), -1))\n",
    "    flat_features = scaler.transform(flat_images)\n",
    "    features = np.reshape(flat_features, (len(images), 28, 28, 1))\n",
    "    return features \n",
    "\n",
    "# Scale both train and test images\n",
    "train_features = scale_features(train_images)\n",
    "test_features = scale_features(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb1e84408d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[idx], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb1e88cd2b0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_features[idx].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzy/.conda/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# we need to tell the encoder about what data it will be dealing with\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(np.reshape(train_labels, (len(train_labels), 1)))\n",
    "\n",
    "# convert labels into one hot encoding\n",
    "def encode_labels(labels):\n",
    "    labels = np.reshape(labels, (len(labels), 1))\n",
    "    features = encoder.transform(labels)\n",
    "    return features\n",
    "                        \n",
    "train_one_hot_labels = encode_labels(train_labels)\n",
    "test_one_hot_labels = encode_labels(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_hot_labels[idx].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "Now we build the Neural Network model that we will train to classify fashion images.\n",
    "\n",
    "A function that adds a convolution block to your model is provided so you don't have to worry about that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolution block to the given sequential model if enabled\n",
    "# layers specify how many convolution layers to use\n",
    "# the scale parameter allows us to scale up the convolution layers\n",
    "def add_conv_block(model, layers, scale, dropout=0.2):\n",
    "        for n_base_filters in range(2, layers * 2 + 1, 2):\n",
    "            model.add(Conv2D(int(n_base_filters * scale), (3, 3),\n",
    "                             padding=\"same\",activation=\"relu\"))\n",
    "            model.add(Conv2D(int(n_base_filters * scale), (3, 3),\n",
    "                             padding=\"same\",activation=\"relu\"))\n",
    "            model.add(Conv2D(int(n_base_filters * scale), (3, 3), \n",
    "                             strides=(2,2), padding=\"same\",activation=\"relu\"))        \n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "        model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Instead of directly building the model, we create a class that exposes its hyperparameters. This will make hyperparameters tuning later easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represents a neural network model\n",
    "class NNModel:\n",
    "    # Create a model with the given hyperparametersz\n",
    "    def __init__(self, \n",
    "                 n_layers,\n",
    "                 learning_rate,\n",
    "                 n_units=64,\n",
    "                 conv_blocks=0,\n",
    "                 conv_scale=0,\n",
    "                 display_summary=False):\n",
    "        \n",
    "        self.input_shape = (28, 28, 1)\n",
    "        self.n_units = n_units\n",
    "        self.n_layers = n_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.conv_scale = conv_scale\n",
    "        self.conv_blocks = conv_blocks\n",
    "        \n",
    "        self.backend_model = self.build()\n",
    "        if display_summary: self.backend_model.summary()\n",
    "        \n",
    "    # Fit the model to the given data\n",
    "    # x - features, y - one hot encoded labels\n",
    "    def fit(self, train_x, train_y, valid_data, n_epochs, batch_size=64):\n",
    "        self.backend_model.fit(train_x, train_y,\n",
    "                               validation_data=valid_data,\n",
    "                               epochs=n_epochs,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "    # Generate predictions using the given features\n",
    "    def predict(self, input_x):\n",
    "        predict_probs = self.backend_model.predict(input_x, \n",
    "                                                 batch_size=64)\n",
    "        predictions = np.argmax(predict_probs, axis=-1)\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    # Build the model\n",
    "    def build(self):\n",
    "        K.clear_session()\n",
    "        \n",
    "        # Build model architecture\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=self.input_shape))\n",
    "        # Convolution layers\n",
    "        add_conv_block(model, \n",
    "                       layers=self.conv_blocks,\n",
    "                       scale=self.conv_scale)\n",
    "        # Dense layers (The brain part)\n",
    "        for i in range(self.n_layers): \n",
    "            model.add(Dense(self.n_units, activation=\"relu\"))\n",
    "            \n",
    "        # Output layer - classfication 10 classes\n",
    "        model.add(Dense(10, activation=\"sigmoid\"))\n",
    "\n",
    "        # Build model\n",
    "        model.compile(optimizer=Adam(lr=self.learning_rate),\n",
    "                      loss=categorical_crossentropy,\n",
    "                      metrics=[categorical_accuracy])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Lets build a model with our model class and train it.\n",
    "As with most machine learning algorithms, there are hyperparameters to tune:\n",
    "\n",
    "| Hyperparameter | Description |\n",
    "| --- | --- |\n",
    "| n_layers | The number of dense/fully connnected layers to use in the model |\n",
    "| n_units | The number of neurons to use each  dense/fully connnected layers |\n",
    "| conv_blocks | The number of convolution blocks use in the model |\n",
    "| conv_scale | Sale\n",
    "\n",
    "We train for 3 epochs, which means that we tell the model to learn from the data by looking at all the data 3 times.\n",
    "> In real world, we train for way more epochs (30-200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 12,730\n",
      "Trainable params: 12,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = NNModel(n_layers=1,\n",
    "                n_units=16, \n",
    "                conv_blocks=0,\n",
    "                conv_scale=12,\n",
    "                learning_rate=3e-3, \n",
    "                display_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.5234 - categorical_accuracy: 0.8069 - val_loss: 0.4546 - val_categorical_accuracy: 0.8337\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3934 - categorical_accuracy: 0.8570 - val_loss: 0.4333 - val_categorical_accuracy: 0.8475\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3649 - categorical_accuracy: 0.8649 - val_loss: 0.4242 - val_categorical_accuracy: 0.8535\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_features, train_one_hot_labels, \n",
    "                 valid_data=(test_features, test_one_hot_labels),\n",
    "                 n_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluting the model\n",
    "One we have have trained the model, we need to evalute how when its doing. We will use the `categorical_accuracy` metric as a yard stick of evaluating how the model is doing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 85.35000000000001% accurate\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_features)\n",
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "print(f\"The model is {accuracy * 100.0}% accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparmeter Tuning\n",
    "Now we make changes to the hyperparameters of models and evalute (Hyperparameter tuning).\n",
    "And then do it again (iterating), trying to get models with higher accuracy.\n",
    "\n",
    "Lets try using more layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.6282 - categorical_accuracy: 0.7871 - val_loss: 0.4507 - val_categorical_accuracy: 0.8402\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3994 - categorical_accuracy: 0.8556 - val_loss: 0.4229 - val_categorical_accuracy: 0.8474\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3671 - categorical_accuracy: 0.8665 - val_loss: 0.4234 - val_categorical_accuracy: 0.8486\n",
      "The model is 84.86% accurate\n"
     ]
    }
   ],
   "source": [
    "model = NNModel(n_layers=2,\n",
    "                n_units=16, \n",
    "                conv_blocks=0,\n",
    "                conv_scale=12,\n",
    "                learning_rate=1e-3,\n",
    "                display_summary=True)\n",
    "                \n",
    "hist = model.fit(train_features, train_one_hot_labels, \n",
    "                 valid_data=(test_features, test_one_hot_labels),\n",
    "                 batch_size=64,\n",
    "                 n_epochs=3)\n",
    "\n",
    "predictions = model.predict(test_features)\n",
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "print(f\"The model is {accuracy * 100.0}% accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm doesn't really help how about some more units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.4934 - categorical_accuracy: 0.8263 - val_loss: 0.4181 - val_categorical_accuracy: 0.8474\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3506 - categorical_accuracy: 0.8712 - val_loss: 0.3875 - val_categorical_accuracy: 0.8612\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3102 - categorical_accuracy: 0.8847 - val_loss: 0.3829 - val_categorical_accuracy: 0.8611\n",
      "The model is 86.11% accurate\n"
     ]
    }
   ],
   "source": [
    "model = NNModel(n_layers=1,\n",
    "                n_units=64, \n",
    "                conv_blocks=0,\n",
    "                conv_scale=12,\n",
    "                learning_rate=1e-3,\n",
    "                display_summary=True)\n",
    "                \n",
    "hist = model.fit(train_features, train_one_hot_labels, \n",
    "                 valid_data=(test_features, test_one_hot_labels),\n",
    "                 batch_size=64,\n",
    "                 n_epochs=3)\n",
    "\n",
    "predictions = model.predict(test_features)\n",
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "print(f\"The model is {accuracy * 100.0}% accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we add some convolution layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 24)        240       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 24)        5208      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 24)        5208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 14, 14, 24)        96        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 24)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4704)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                301120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 312,522\n",
      "Trainable params: 312,474\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 16s 266us/sample - loss: 0.4197 - categorical_accuracy: 0.8488 - val_loss: 0.3181 - val_categorical_accuracy: 0.8833\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 0.2646 - categorical_accuracy: 0.9020 - val_loss: 0.2988 - val_categorical_accuracy: 0.8956\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 16s 274us/sample - loss: 0.2137 - categorical_accuracy: 0.9187 - val_loss: 0.2839 - val_categorical_accuracy: 0.9005\n",
      "The model is 90.05% accurate\n"
     ]
    }
   ],
   "source": [
    "model = NNModel(n_layers=1,\n",
    "                n_units=64, \n",
    "                conv_blocks=1,\n",
    "                conv_scale=12,\n",
    "                learning_rate=1e-3,\n",
    "                display_summary=True)\n",
    "                \n",
    "hist = model.fit(train_features, train_one_hot_labels, \n",
    "                 valid_data=(test_features, test_one_hot_labels),\n",
    "                 batch_size=64,\n",
    "                 n_epochs=3)\n",
    "\n",
    "predictions = model.predict(test_features)\n",
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "print(f\"The model is {accuracy * 100.0}% accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution layers gave us ~4% accuracy increase!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are on a time limit today thats all that we will will try. But i suggest that you try other values.\n",
    "\n",
    ">Neural Networks are able scale to large amount of data, but require large amount of computing resources use effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
