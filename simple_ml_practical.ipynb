{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General ML Crash Course\n",
    "Notebook written by Ze Ming :l and Joel\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Participate and make submissions in Kaggle competitions\n",
    "2. Explain the difference between supervised and unsupervised problems\n",
    "3. Create a machine learning model by fitting data into a model provided by scikit.\n",
    "\n",
    "In this notebook, we will be using the Boston housing problem on [Kaggle](https://www.kaggle.com/c/boston-housing/overview) as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Boston Housing Prices\n",
    "**Sign up and download the data here: https://www.kaggle.com/c/boston-housing/data**\n",
    "\n",
    "The zip archive contains three files:\n",
    "\n",
    "- train.csv\n",
    "- test.csv\n",
    "- submission_example.csv\n",
    "\n",
    "`train.csv` is the dataset which you use to teach your machine learning model.\n",
    "\n",
    "`test.csv` contains tests which Kaggle uses to assess your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T10:04:30.514269Z",
     "start_time": "2019-05-08T10:04:24.298848Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T10:04:30.663423Z",
     "start_time": "2019-05-08T10:04:30.516262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the training data and test data into pandas dataframes\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T10:04:30.729029Z",
     "start_time": "2019-05-08T10:04:30.666291Z"
    }
   },
   "outputs": [],
   "source": [
    "# Explore the train data with .head()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the train data with .head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguishing supervised and unsupervised problems\n",
    "\n",
    "A *supervised problem* is the problem of finding a relationship between two data sets where one data set is the input, and the other is the expected output.\n",
    "\n",
    "In this case, we are finding the relationship between:\n",
    "- (Input) some information about the town in Boston\n",
    "- (Expected Output) price of a house in that town\n",
    "\n",
    "\n",
    "An *unsupervised problem* is the problem of finding a certain pattern in a data set. The key difference is that there is no expected output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many competitions will provide you with the dataset (such as now) and, just by looking through the dataset, you will be able to tell whether it is a supervised or unsupervised problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition, we need to submit a csv file with our answers, given the test rows in `test.csv`.\n",
    "\n",
    "Since the `train.csv` dataset contains input and expected output data, this is a supervised problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The library that we will be using for machine learning this time will be scikit-learn. \n",
    "\n",
    "Scikit-learn is also very useful because most models are used in the same way: `.fit()`/`.train()` and some other methods apply to most models.\n",
    "\n",
    "So any time you find yourself wanting to try another type of algorithm for your dataset, just swap it out and it should work fine.\n",
    "\n",
    "For example, you can comment `RandomForestRegressor` and uncomment `SVR`, both should still work. Some models like `SVR` and `RandomForestRegressor` also come with hyper-parameters for you to tune the algorithm to possibly get better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:52.635768Z",
     "start_time": "2019-05-07T12:17:52.630780Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:18:13.676118Z",
     "start_time": "2019-05-07T12:18:13.673109Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "# model = SVR(C=1e+2, gamma=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing some exploration, you will observe that several factors seem to affect the median price:\n",
    "\n",
    "* rm\n",
    "* lstat\n",
    "* crim\n",
    "* rad\n",
    "* indus\n",
    "\n",
    "So, we are only going to use a few of these columns for training the model.\n",
    "\n",
    "Feel free to adjust what columns you use to train the model. `pandas` makes it convenient by allowing you to plug and play the column names.\n",
    "\n",
    "In this case, I will use `rm`, `lstat` and `crim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:53.014137Z",
     "start_time": "2019-05-07T12:17:53.003169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the factors which seem to affect the median price\n",
    "X = train_df[['rm', 'lstat', 'crim']]\n",
    "# Extract the median price\n",
    "Y = train_df['medv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be good to be able to tell the accuracy of our model after training it. So, we split the given dataset (`train.csv`) into two: one for training and the other for testing the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:53.254020Z",
     "start_time": "2019-05-07T12:17:53.247010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data, with 30% of the data as test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:53.372017Z",
     "start_time": "2019-05-07T12:17:53.367028Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:53.504865Z",
     "start_time": "2019-05-07T12:17:53.483920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:55.420927Z",
     "start_time": "2019-05-07T12:17:55.411922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Score the model based on default scorer (R2)\n",
    "print(model.score(X_test, Y_test))\n",
    "\n",
    "# Score the model based on RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "print(sqrt(mean_squared_error(Y_test, Y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score here will always vary, as the dataset is quite small (400~)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "Scikit-Learn calculates the score by testing the model with `X_test` \"questions\". Then it compares the model's \"answers\" with the `Y_test` (`Y_test` is the correct answer). Since the dataset is small, the test size is also small. This means that the result can change all the time. This issue does not happen with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you should be able to achieve at least >0.5 score for R2. (predictions are more than 50% correct when tested)\n",
    "\n",
    "There are two scoring methods used here. The first is R2 and the second one is RMSE. R2 can give you a rough idea of \"accuracy\". RMSE is used here because that is what Kaggle is judging you by. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the submission CSV file\n",
    "Kaggle provides a `test.csv` file which contains data on towns in Boston but does not contain the price of housing in that town. This is the set of \"questions\" which Kaggle uses to assess your model.\n",
    "\n",
    "Let's do the same process to predict the price of housing in the `test.csv` towns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:56.329991Z",
     "start_time": "2019-05-07T12:17:56.324007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take the same features that you used previously to train your model\n",
    "predict_from = test_df[['rm', 'lstat', 'crim']]\n",
    "predict_from.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:17:56.769146Z",
     "start_time": "2019-05-07T12:17:56.765157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataframe to be used for submission\n",
    "predicted = model.predict(predict_from)\n",
    "submission_df = pd.DataFrame({'ID' : test_df['ID'], \"medv\" : predicted})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas makes making CSVs very easy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:09:57.580830Z",
     "start_time": "2019-05-07T12:09:57.557891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write the dataframe into a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you submit `submission.csv` to the competition and view your score. The lower your score the better since they are using a different method of scoring (RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "As mentioned before, the machine learning model may accept additional parameters to tune the underlying alogrithm. These are called *hyperparameters*. We won't go through how to find the best values, but, just to show the effects, here are a few good values to try out:\n",
    "\n",
    "```\n",
    "n_estimators=279, max_depth=682, max_features=2\n",
    "n_estimators=45, max_depth=703, max_features=2\n",
    "n_estimators=61, max_depth=166, max_features=3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parameters in the model\n",
    "model = RandomForestRegressor(n_estimators=279, max_depth=682, max_features=2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Score the model based on default scorer (R2)\n",
    "print(model.score(X_test, Y_test))\n",
    "\n",
    "# Score the model based on RMSE\n",
    "Y_predicted = model.predict(X_test)\n",
    "print(sqrt(mean_squared_error(Y_test, Y_predicted)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
